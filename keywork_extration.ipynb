{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,codecs\n",
    "import jieba.posseg\n",
    "import jieba.analyse\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\"\"\"\n",
    "       TF-IDF权重：\n",
    "           1、CountVectorizer 构建词频矩阵\n",
    "           2、TfidfTransformer 构建tfidf权值计算\n",
    "           3、文本的关键字\n",
    "           4、对应的tfidf矩阵\n",
    "\"\"\"\n",
    "# 数据预处理操作：分词，去停用词，词性筛选\n",
    "def dataPrepos(text, stopkey):\n",
    "    l = []\n",
    "    pos = ['n', 'nz', 'v', 'vd', 'vn', 'l', 'a', 'd']  # 定义选取的词性\n",
    "    seg = jieba.posseg.cut(text)  # 分词\n",
    "    for i in seg:\n",
    "        if i.word not in stopkey and i.flag in pos:  # 去停用词 + 词性筛选\n",
    "            l.append(i.word)\n",
    "    return l\n",
    "\n",
    "# tf-idf获取文本top10关键词\n",
    "def getKeywords_tfidf(data,stopkey,topK):\n",
    "    idList, titleList, abstractList = data['id'], data['title'], data['abstract']\n",
    "    corpus = [] # 将所有文档输出到一个list中，一行就是一个文档\n",
    "    for index in range(len(idList)):\n",
    "        text = '%s。%s' % (titleList[index], abstractList[index]) # 拼接标题和摘要\n",
    "        text = dataPrepos(text,stopkey) # 文本预处理\n",
    "        text = \" \".join(text) # 连接成字符串，空格分隔\n",
    "        corpus.append(text)\n",
    "\n",
    "    # 1、构建词频矩阵，将文本中的词语转换成词频矩阵\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus) # 词频矩阵,a[i][j]:表示j词在第i个文本中的词频\n",
    "    # 2、统计每个词的tf-idf权值\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(X)\n",
    "    # 3、获取词袋模型中的关键词\n",
    "    word = vectorizer.get_feature_names()\n",
    "    # 4、获取tf-idf矩阵，a[i][j]表示j词在i篇文本中的tf-idf权重\n",
    "    weight = tfidf.toarray()\n",
    "    # 5、打印词语权重\n",
    "    ids, titles, keys = [], [], []\n",
    "    for i in range(len(weight)):\n",
    "#        print(u\"-------这里输出第\", i+1 , u\"篇文本的词语tf-idf------\")\n",
    "        ids.append(idList[i])\n",
    "        titles.append(titleList[i])\n",
    "        df_word,df_weight = [],[] # 当前文章的所有词汇列表、词汇对应权重列表\n",
    "        for j in range(len(word)):\n",
    "#            print(word[j],weight[i][j])\n",
    "            df_word.append(word[j])\n",
    "            df_weight.append(weight[i][j])\n",
    "        df_word = pd.DataFrame(df_word,columns=['word'])\n",
    "        df_weight = pd.DataFrame(df_weight,columns=['weight'])\n",
    "        word_weight = pd.concat([df_word, df_weight], axis=1) # 拼接词汇列表和权重列表\n",
    "        word_weight = word_weight.sort_values(by=\"weight\",ascending = False) # 按照权重值降序排列\n",
    "        keyword = np.array(word_weight['word']) # 选择词汇列并转成数组格式\n",
    "        word_split = [keyword[x] for x in range(0,topK)] # 抽取前topK个词汇作为关键词\n",
    "        word_split = \" \".join(word_split)\n",
    "        keys.append(word_split)\n",
    "    result = pd.DataFrame({\"id\": ids, \"title\": titles, \"key\": keys},columns=['id','title','key'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'posts/{comp[7]}.csv')\n",
    "result = getKeywords_tfidf(data,stopwords,20)\n",
    "result.to_csv(f\"result/{comp[7]}.csv\",index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, store_list):\n",
    "    with open(f'{path}.txt',errors='ignore',encoding = \"utf-8\") as f:\n",
    "        for line in f:\n",
    "            words = line.strip()\n",
    "            if words not in store_list:\n",
    "                store_list.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stopwords 中文停用词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "\n",
    "path_baidu = 'stopwords/baidu_stopwords'\n",
    "path_siculab = 'stopwords/scu_stopwords'\n",
    "path_noram = 'stopwords/cn_stopwords'\n",
    "\n",
    "read_file(path_baidu,stopwords)\n",
    "read_file(path_siculab,stopwords)\n",
    "read_file(path_noram,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append('知乎')\n",
    "stopwords.append('一个')\n",
    "stopwords.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # 读取数据集\n",
    "#     dataFile = 'data/sample_data.csv'\n",
    "#     data = pd.read_csv(dataFile)\n",
    "#     # 停用词表\n",
    "#     stopkey = [w.strip() for w in codecs.open('data/stopWord.txt', 'r').readlines()]\n",
    "#     # tf-idf关键词抽取\n",
    "#     result = getKeywords_tfidf(data,stopkey,10)\n",
    "#     result.to_csv(\"result/keys_TFIDF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [172,98,16,28,136,10,20,20,163,17,71,5,49,53,38,311,139,45,21,109,769,156,181,18,8]\n",
    "comp = ['teng-xun-70','teng-xun-ke-ji','tian-mei-gong-zuo-shi-21','weda-hui','teng-xun-yun-4','teng-yun-zhi-ku','teng-xun-yi-dian','teng-xun-dong-man','teng-xun-li-cai-tong-48','wei-xin-93-75','teng-xun-yan-jiu-yuan-28','teng-xun-fang-shui-qiang','wei-xin-zhi-fu-30','teng-xun-da-xue','teng-xun-you-xi-an-quan','teng-xun-ji-zhu-gong-cheng','teng-xun-wetest-74','teng-xun-da-shu-ju','teng-xun-qq-60','teng-xun-bugly','teng-xun-yun-ji-zhu-she-qu','teng-xun-shou-hu-zhe-ji-hua','teng-xun-an-quan-lian-he-shi-yan-shi','teng-xun-fan-yi-jun','qq-yin-yue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comp:\n",
    "    data = pd.read_csv(f'tenx_posts/{i}.csv')\n",
    "    result = getKeywords_tfidf(data,stopwords,10)\n",
    "    result.to_csv(f\"result/{i}.csv\",index=False,encoding='utf_8_sig')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把 文章储存在csv 文件里\n",
    "# for i in range(len(comp)):\n",
    "#     id_ = 0\n",
    "#     temp = {'id':[],'title':[],'abstract':[]}\n",
    "#     path = f'tenx_posts/{comp[i]}'\n",
    "#     for n in range(ls[i]):\n",
    "#         try:\n",
    "#             with open(f'{path}/{n}.txt',encoding = \"gb18030\") as f:\n",
    "#                 con = 0\n",
    "#                 for line in f:\n",
    "#                     if con == 0:\n",
    "#                         if line.strip() != '':\n",
    "#                             temp['title'].append(line.strip())\n",
    "#                         else:\n",
    "#                             temp['title'].append('')\n",
    "#                     elif con == 2:\n",
    "#                         temp['abstract'].append(line.strip())\n",
    "#                     con+=1\n",
    "#                 if con != 3:\n",
    "#                     temp['abstract'].append('')\n",
    "#                 temp['id'].append(id_)\n",
    "#                 id_ += 1\n",
    "\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     temp = pd.DataFrame(temp)\n",
    "#     temp.to_csv(f\"tenx_posts/{comp[i]}.csv\",index=False,encoding='utf_8_sig')\n",
    "# # result = getKeywords_tfidf(temp,stopwords,10)\n",
    "# # result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "  # 对句子进行中文分词\n",
    "def seg_depart(sentence): # stopwords\n",
    "    sentence_depart = jieba.cut(sentence)\n",
    "\n",
    "    # 输出结果为outstr\n",
    "    outstr = ''\n",
    "    # 去停用词\n",
    "    for word in sentence_depart:\n",
    "        if word not in stopwords:\n",
    "            outstr += word\n",
    "            outstr += \" \"\n",
    "    return outstr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_visual(file_name,n_features,n_topics,n_top_words): # 文件名，关键词个数，主题个数, 打印主题个数\n",
    "    # load file & separate words\n",
    "    temp = []\n",
    "    path = f'posts/{file_name}'\n",
    "    with open(f'{path}.txt',encoding = \"gb18030\") as f: # ①把编码方式utf-8 修改为gb18030, ②把原来的txt文件重新打开另存为的时候，把编码方式修改为utf-8，然后代码的encoding=‘utf-8’保持不变即可\n",
    "        for line in f:\n",
    "            words = line.strip()\n",
    "            temp.append(seg_depart(words))\n",
    "    \n",
    "    # 文本向量转换\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "    tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                    max_features=n_features,\n",
    "                                    stop_words=stopwords,\n",
    "                                    max_df = 0.5,\n",
    "                                    min_df = 1)\n",
    "    tf = tf_vectorizer.fit_transform(temp)\n",
    "    # fit LDA\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=50,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)\n",
    "    lda.fit(tf)\n",
    "    \n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, n_top_words)\n",
    "    return lda, tf, tf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = ['wan-mei-shi-jie-48-2','zhi-fu-bao-72-4','teng-xun-ke-ji','jing-dong-46-34','teng-xun-70','a-li-ba-ba-23-79','da-zhong-dian-ping-83']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wan-mei-shi-jie-48-2 :\n",
      "Topic #0:\n",
      "动画 2019 作品 2018 制作 市场 企业 合作 行业 业务\n",
      "Topic #1:\n",
      "场景 制作 工作 专业 成功 玩家 团队 文化 技术 洪恩\n",
      "Topic #2:\n",
      "冰糖 雪梨 观众 专业 该剧 青春 制作 团队 电视剧 成功\n",
      "Topic #3:\n",
      "行业 发展 业务 文创 企业 文化 未来 领域 技术 内容\n",
      "Topic #4:\n",
      "冰糖 黎语 雪梨 青春 梦想 爱情 少年 甜蜜 观众 电视剧\n",
      "Topic #5:\n",
      "团队 市场 研发 产品 工作 技术 玩家 手游 洪恩 行业\n",
      "Topic #6:\n",
      "作品 雪梨 该剧 观众 剧集 冰糖 15 专业 青春 带来\n",
      "Topic #7:\n",
      "青春 观众 全世界 优酷 剧集 热血 该剧 电视剧 爱情 文化\n",
      "Topic #8:\n",
      "王雨蕴 合作 市场 产品 行业 团队 企业 梦想 工作 未来\n",
      "Topic #9:\n",
      "带来 玩家 手游 成功 内容 雪梨 冰糖 黎语 观众 团队\n",
      "\n",
      "\n",
      "zhi-fu-bao-72-4 :\n",
      "Topic #0:\n",
      "蚂蚁 区块 金服 数据 团队 系统 业务 场景 工作 公司\n",
      "Topic #1:\n",
      "蚂蚁 阿里 森林 工程师 杭州 数据 中国 公司 互联网 科技\n",
      "Topic #2:\n",
      "账户 手机 信息 系统 支付 平台 希望 10 团队 提供\n",
      "Topic #3:\n",
      "支付 中国 手机 11 场景 全球 体验 服务 希望 上线\n",
      "Topic #4:\n",
      "保障 风险 相互 蚂蚁 金服 平台 能力 金融 系统 服务\n",
      "Topic #5:\n",
      "服务 程序 提供 平台 上线 超过 业务 生活 蚂蚁 体验\n",
      "Topic #6:\n",
      "公司 支持 项目 希望 时间 未来 10 工作 生活 提供\n",
      "Topic #7:\n",
      "城市 电子 杭州 全国 服务 未来 支持 时间 上线 超过\n",
      "Topic #8:\n",
      "信用 商家 体验 产品 11 解决 10 风险 未来 能力\n",
      "Topic #9:\n",
      "中国 全球 互联网 发展 科技 平台 生活 服务 工作 信息\n",
      "\n",
      "\n",
      "teng-xun-ke-ji :\n",
      "Topic #0:\n",
      "5g 网络 亿元 全球 2017 人工智能 2014 资本 手机 华为\n",
      "Topic #1:\n",
      "手机 oppo facebook 华为 苹果 渠道 小米 品牌 国内 销售\n",
      "Topic #2:\n",
      "滴滴 ofo 合并 城市 融资 竞争 资本 亿美元 创业 机会\n",
      "Topic #3:\n",
      "亚马逊 内容 netflix 竞争 机会 网络 亿美元 电视 销售 苹果\n",
      "Topic #4:\n",
      "百度 万达 网易 电商 游戏 内部 战略 2017 苹果 2014\n",
      "Topic #5:\n",
      "小米 特斯拉 联想 手机 汽车 印度 销售 品牌 内部 亿美元\n",
      "Topic #6:\n",
      "乐视 亿元 贾跃亭 2014 资金 万达 融资 资本 国内 谷歌\n",
      "Topic #7:\n",
      "人工智能 创业 上市 ipo 工作 亿美元 机会 资本 小米 融资\n",
      "Topic #8:\n",
      "乐视 贾跃亭 谷歌 电视 资金 汽车 生态 手机 亿元 战略\n",
      "Topic #9:\n",
      "印度 手机 国内 oppo 品牌 小米 销售 华为 2017 苹果\n",
      "\n",
      "\n",
      "jing-dong-46-34 :\n",
      "Topic #0:\n",
      "京喜 直播 商家 市场 企业 合作 中国 活动 销售 商品\n",
      "Topic #1:\n",
      "企业 物流 智能 供应链 技术 物资 复工 保障 能力 配送\n",
      "Topic #2:\n",
      "增长 同比 成交额 消费 数据 商品 超过 品类 销售 全国\n",
      "Topic #3:\n",
      "家电 新品 体验 消费 推出 品类 生活 活动 联合 打造\n",
      "Topic #4:\n",
      "直播 活动 线上 线下 复工 销售 渠道 联合 模式 行业\n",
      "Topic #5:\n",
      "商家 支持 物流 商品 推出 保障 资源 提升 超过 消费\n",
      "Topic #6:\n",
      "湖北 武汉 物资 物流 全国 配送 生活 超过 保障 商品\n",
      "Topic #7:\n",
      "超市 门店 商品 销售 合作 零售 线上 线下 渠道 市场\n",
      "Topic #8:\n",
      "生鲜 销售 零售 全国 供应链 渠道 物流 资源 超过 能力\n",
      "Topic #9:\n",
      "健康 保障 推出 企业 联合 线上 全国 上线 中国 门店\n",
      "\n",
      "\n",
      "teng-xun-70 :\n",
      "Topic #0:\n",
      "ai 模型 数据 研究 团队 识别 领域 能力 一种 系统\n",
      "Topic #1:\n",
      "游戏 角色 视觉 设计 合作 活动 平台 数据 发展 中国\n",
      "Topic #2:\n",
      "设计 操作 内容 场景 信息 页面 体验 过程 方式 发现\n",
      "Topic #3:\n",
      "互联网 中国 发展 产业 未来 企业 领域 公司 希望 服务\n",
      "Topic #4:\n",
      "程序 微信 信息 一种 平台 希望 手机 页面 时间 游戏\n",
      "Topic #5:\n",
      "图片 颜色 识别 效果 模型 设计 数据 简单 视觉 过程\n",
      "Topic #6:\n",
      "qq 品牌 设计 视觉 一种 希望 模型 信息 系统 颜色\n",
      "Topic #7:\n",
      "公益 活动 项目 平台 品牌 能力 场景 效果 方式 企业\n",
      "Topic #8:\n",
      "需求 系统 简单 数据 服务 效果 方式 过程 信息 能力\n",
      "Topic #9:\n",
      "视频 体验 功能 团队 手机 qq 方式 发现 场景 时间\n",
      "\n",
      "\n",
      "a-li-ba-ba-23-79 :\n",
      "Topic #0:\n",
      "阿里 20 杭州 未来 同学 世界 10 社会 成功 选择\n",
      "Topic #1:\n",
      "经济 数字 数据 数字化 时代 发展 计算 商业 大会 社会\n",
      "Topic #2:\n",
      "病毒 物资 捐赠 平台 免费 医疗 阿里 小时 时间 菜鸟\n",
      "Topic #3:\n",
      "平台 全球 疫情 物资 医疗 企业 口罩 世界 同学 公益\n",
      "Topic #4:\n",
      "商家 埃塞 经济 免费 平台 提供 数字 疫情 服务 天猫\n",
      "Topic #5:\n",
      "日本 马云 物资 口罩 中国 疫情 希望 公益 医疗 捐赠\n",
      "Topic #6:\n",
      "免费 小时 医疗 10 服务 公益 公司 菜鸟 捐赠 阿里\n",
      "Topic #7:\n",
      "全球 未来 20 使命 数字 时代 经济 公司 10 社会\n",
      "Topic #8:\n",
      "996 工作 阿里 小时 公司 员工 选择 成功 努力 希望\n",
      "Topic #9:\n",
      "11 天猫 小时 10 中国 全球 时间 成功 马云 口罩\n",
      "\n",
      "\n",
      "da-zhong-dian-ping-83 :\n",
      "Topic #0:\n",
      "奶茶 一口 味道 这家 浓郁 风格 口感 选择 上海 大众\n",
      "Topic #1:\n",
      "温泉 蛋糕 推荐 享受 感觉 更是 北京 体验 一口 适合\n",
      "Topic #2:\n",
      "打卡 上海 时间 艺术 体验 历史 建筑 00 世界 地址\n",
      "Topic #3:\n",
      "味道 北京 城市 上海 传统 美食 一口 口感 火锅 浓郁\n",
      "Topic #4:\n",
      "美食 中国 餐厅 食物 大众 食材 生活 火锅 味道 世界\n",
      "Topic #5:\n",
      "餐厅 这家 口感 味道 美味 一口 搭配 浓郁 美食 一家\n",
      "Topic #6:\n",
      "选择 00 食物 环境 餐厅 更是 生活 口感 仿佛 上海\n",
      "Topic #7:\n",
      "生活 00 艺术 世界 城市 上海 更是 喜欢 大众 地址\n",
      "Topic #8:\n",
      "食物 选择 环境 真的 精致 这家 美味 体验 餐厅 特别\n",
      "Topic #9:\n",
      "地址 生活 地方 感觉 一种 精致 城市 喜欢 适合 味道\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! pip install pyldavis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "for i in comp:\n",
    "    print(i,':')\n",
    "    lda, tf, tf_vectorizer = topic_visual(i,50,10,10)\n",
    "    #pyLDAvis.enable_notebook()\n",
    "    #pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bai-du-81-39 :\n",
      "Topic #0:\n",
      "拒绝 蝙蝠 保护 公共卫生 野味\n",
      "Topic #1:\n",
      "复工 指数 地图 城市 全国\n",
      "Topic #2:\n",
      "网络 黑产 报告 复工 企业\n",
      "Topic #3:\n",
      "黑产 规模 网络 犯罪 治理\n",
      "Topic #4:\n",
      "热度 产业 知识 教育 公共卫生\n"
     ]
    }
   ],
   "source": [
    "name = 'bai-du-81-39'\n",
    "print(name,':')\n",
    "lda, tf, tf_vectorizer = topic_visual(name,100,5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = [76,296,98,568,172,45,79,7]\n",
    "# comp = ['wan-mei-shi-jie-48-2','zhi-fu-bao-72-4','teng-xun-ke-ji','jing-dong-46-34','teng-xun-70','a-li-ba-ba-23-79','da-zhong-dian-ping-83','bai-du-81-39']\n",
    "\n",
    "# def merge(name,l):\n",
    "#     temp = []\n",
    "#     path = f'posts/{name}'\n",
    "#     title = []\n",
    "#     for n in range(l):\n",
    "#         try:\n",
    "#             with open(f'{path}/{n}.txt',encoding = \"gb18030\") as f:\n",
    "#                 con = 0\n",
    "#                 post = ''\n",
    "#                 for line in f:\n",
    "#                     if con == 0:\n",
    "#                         post += line.strip()\n",
    "#                     elif con == 2:\n",
    "#                         post += line.strip()\n",
    "#                     con+=1\n",
    "#                 temp.append(post)\n",
    "#         except:\n",
    "#             pass\n",
    "#     for n in range(l):\n",
    "#         with open(f'{path}.txt','w',encoding = \"gb18030\") as f:\n",
    "#             for i in temp:\n",
    "#                 f.write(i+'\\n')\n",
    "\n",
    "\n",
    "# for i in range(len(ls)):\n",
    "#     merge(comp[i],ls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = ['wan-mei-shi-jie-48-2','zhi-fu-bao-72-4','teng-xun-ke-ji','jing-dong-46-34','teng-xun-70','a-li-ba-ba-23-79','da-zhong-dian-ping-83']\n",
    "names = ['完美世界','支付宝','腾讯科技','京东','腾讯','阿里巴巴','大众点评']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jieba.analyse import *\n",
    "for i in range(len(comp)):\n",
    "    file = pd.read_csv(f'result/{comp[i]}.csv')\n",
    "    data = ''\n",
    "    for j in file['key']:\n",
    "        data += j\n",
    "    data = seg_depart(data)\n",
    "    df1 = {'keyword':[],'weight':[]}\n",
    "    for keyword, weight in extract_tags(data, topK=10, withWeight=True):\n",
    "        df1['keyword'].append(keyword)\n",
    "        df1['weight'].append(weight)\n",
    "    df2 = {'keyword':[],'weight':[]}\n",
    "    for keyword, weight in textrank(data, withWeight=True):\n",
    "        df2['keyword'].append(keyword)\n",
    "        df2['weight'].append(weight)\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df2 = pd.DataFrame(df2)\n",
    "    df1.to_csv(f\"result/{comp[i]}_tag.csv\",index=False,encoding='utf_8_sig')\n",
    "    df2.to_csv(f\"result/{comp[i]}_textrank.csv\",index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(comp)):\n",
    "    file = pd.read_csv(f'result/{comp[i]}.csv')\n",
    "    data = ''\n",
    "    for j in file['title']:\n",
    "        data += j\n",
    "    data = seg_depart(data)\n",
    "    df1 = {'keyword':[],'weight':[]}\n",
    "    for keyword, weight in extract_tags(data, topK=10, withWeight=True):\n",
    "        df1['keyword'].append(keyword)\n",
    "        df1['weight'].append(weight)\n",
    "    df2 = {'keyword':[],'weight':[]}\n",
    "    for keyword, weight in textrank(data, withWeight=True):\n",
    "        df2['keyword'].append(keyword)\n",
    "        df2['weight'].append(weight)\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df2 = pd.DataFrame(df2)\n",
    "    df1.to_csv(f\"result/{comp[i]}_title_tag.csv\",index=False,encoding='utf_8_sig')\n",
    "    df2.to_csv(f\"result/{comp[i]}_title_textrank.csv\",index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看各个公司文章的关键字|\n",
    "['腾讯科技', '腾讯', '微信支付', '腾讯技术工程', '腾讯安全联合实验室', '腾讯医典', '腾讯云技术社区']\n",
    "\n",
    "'[    0          ,      1     ,      2           ,        3               ,                4             ,            5          ,            6]'\n",
    "\n",
    "['teng-xun-ke-ji', 'teng-xun-70', 'wei-xin-zhi-fu-30', 'teng-xun-ji-zhu-gong-cheng', 'teng-xun-an-quan-lian-he-shi-yan-shi', 'teng-xun-yi-dian', 'teng-xun-yun-ji-zhu-she-qu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['teng-xun-ke-ji', 'teng-xun-70', 'wei-xin-zhi-fu-30', 'teng-xun-ji-zhu-gong-cheng', 'teng-xun-an-quan-lian-he-shi-yan-shi', 'teng-xun-yi-dian', 'teng-xun-yun-ji-zhu-she-qu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teng-xun-an-quan-lian-he-shi-yan-shi'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokens[-3]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>腾讯</td>\n",
       "      <td>0.206628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>木马</td>\n",
       "      <td>0.186027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>挖矿</td>\n",
       "      <td>0.183858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>攻击</td>\n",
       "      <td>0.152561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>病毒</td>\n",
       "      <td>0.143831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>漏洞</td>\n",
       "      <td>0.139813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>电脑</td>\n",
       "      <td>0.094576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>数据安全</td>\n",
       "      <td>0.093920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>企业</td>\n",
       "      <td>0.081863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>网络安全</td>\n",
       "      <td>0.070754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword    weight\n",
       "0      腾讯  0.206628\n",
       "1      木马  0.186027\n",
       "2      挖矿  0.183858\n",
       "3      攻击  0.152561\n",
       "4      病毒  0.143831\n",
       "5      漏洞  0.139813\n",
       "6      电脑  0.094576\n",
       "7    数据安全  0.093920\n",
       "8      企业  0.081863\n",
       "9    网络安全  0.070754"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"result/{x}_tag.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>攻击</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>企业</td>\n",
       "      <td>0.823110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>病毒</td>\n",
       "      <td>0.753241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>漏洞</td>\n",
       "      <td>0.746579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>木马</td>\n",
       "      <td>0.739186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>挖矿</td>\n",
       "      <td>0.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>电脑</td>\n",
       "      <td>0.547735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>数据</td>\n",
       "      <td>0.516221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>业务</td>\n",
       "      <td>0.394532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>实验室</td>\n",
       "      <td>0.392453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>文件</td>\n",
       "      <td>0.327581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>服务器</td>\n",
       "      <td>0.324148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>防护</td>\n",
       "      <td>0.317536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>数据安全</td>\n",
       "      <td>0.302202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>管家</td>\n",
       "      <td>0.295535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>传播</td>\n",
       "      <td>0.291630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>用户</td>\n",
       "      <td>0.280633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>产业</td>\n",
       "      <td>0.250545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>手机</td>\n",
       "      <td>0.232596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>议题</td>\n",
       "      <td>0.222080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword    weight\n",
       "0       攻击  1.000000\n",
       "1       企业  0.823110\n",
       "2       病毒  0.753241\n",
       "3       漏洞  0.746579\n",
       "4       木马  0.739186\n",
       "5       挖矿  0.667000\n",
       "6       电脑  0.547735\n",
       "7       数据  0.516221\n",
       "8       业务  0.394532\n",
       "9      实验室  0.392453\n",
       "10      文件  0.327581\n",
       "11     服务器  0.324148\n",
       "12      防护  0.317536\n",
       "13    数据安全  0.302202\n",
       "14      管家  0.295535\n",
       "15      传播  0.291630\n",
       "16      用户  0.280633\n",
       "17      产业  0.250545\n",
       "18      手机  0.232596\n",
       "19      议题  0.222080"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"result/{x}_textrank.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>腾讯</td>\n",
       "      <td>0.419259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.175314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>挖矿</td>\n",
       "      <td>0.154499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>木马</td>\n",
       "      <td>0.140689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>病毒</td>\n",
       "      <td>0.124317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>产业</td>\n",
       "      <td>0.103035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>报告</td>\n",
       "      <td>0.094605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>电脑</td>\n",
       "      <td>0.093295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>勒索</td>\n",
       "      <td>0.087588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>专家</td>\n",
       "      <td>0.082151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword    weight\n",
       "0      腾讯  0.419259\n",
       "1    2018  0.175314\n",
       "2      挖矿  0.154499\n",
       "3      木马  0.140689\n",
       "4      病毒  0.124317\n",
       "5      产业  0.103035\n",
       "6      报告  0.094605\n",
       "7      电脑  0.093295\n",
       "8      勒索  0.087588\n",
       "9      专家  0.082151"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"result/{x}_title_tag.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>企业</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>木马</td>\n",
       "      <td>0.995104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>病毒</td>\n",
       "      <td>0.931210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>报告</td>\n",
       "      <td>0.887339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>挖矿</td>\n",
       "      <td>0.844452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>全球</td>\n",
       "      <td>0.704230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>攻击</td>\n",
       "      <td>0.659433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>电脑</td>\n",
       "      <td>0.633901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>产业</td>\n",
       "      <td>0.585073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>漏洞</td>\n",
       "      <td>0.544100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>发布</td>\n",
       "      <td>0.478256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>互联网</td>\n",
       "      <td>0.459871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>管家</td>\n",
       "      <td>0.438346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>数据</td>\n",
       "      <td>0.415263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>专家</td>\n",
       "      <td>0.396995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>做好</td>\n",
       "      <td>0.384989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>数据安全</td>\n",
       "      <td>0.376148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>助力</td>\n",
       "      <td>0.354964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>技术</td>\n",
       "      <td>0.328823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>实验室</td>\n",
       "      <td>0.322293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword    weight\n",
       "0       企业  1.000000\n",
       "1       木马  0.995104\n",
       "2       病毒  0.931210\n",
       "3       报告  0.887339\n",
       "4       挖矿  0.844452\n",
       "5       全球  0.704230\n",
       "6       攻击  0.659433\n",
       "7       电脑  0.633901\n",
       "8       产业  0.585073\n",
       "9       漏洞  0.544100\n",
       "10      发布  0.478256\n",
       "11     互联网  0.459871\n",
       "12      管家  0.438346\n",
       "13      数据  0.415263\n",
       "14      专家  0.396995\n",
       "15      做好  0.384989\n",
       "16    数据安全  0.376148\n",
       "17      助力  0.354964\n",
       "18      技术  0.328823\n",
       "19     实验室  0.322293"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"result/{x}_title_textrank.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
